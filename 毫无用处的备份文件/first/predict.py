"""
è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç¨‹åº - ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼ˆä¿®å¤ç‰ˆï¼‰
=======================================

åŠŸèƒ½ï¼š
1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œæ•°æ®å¤„ç†å™¨
2. å¯¹æ–°çš„è‚¡ç¥¨æ•°æ®è¿›è¡Œé¢„æµ‹
3. å¯è§†åŒ–é¢„æµ‹ç»“æœ
4. è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡å’Œè¯¯å·®æŒ‡æ ‡
5. é¢„æµ‹7æœˆ1å·è‚¡å¸‚æƒ…å†µå¹¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š

ä½œè€…ï¼šAI Assistant
åˆ›å»ºæ—¶é—´ï¼š2024å¹´
ä¿®å¤æ—¶é—´ï¼š2025å¹´
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import os
import pickle
import warnings
import sys
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import MinMaxScaler

warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from learn.models.transformer_model import StockTransformer, AdvancedStockTransformer
from data.data_processor import StockDataProcessor

class StockPredictor:
    """è‚¡ç¥¨ä»·æ ¼é¢„æµ‹å™¨"""
    
    def __init__(self, model_path="../../models/best_model.pth"):
        """åˆå§‹åŒ–é¢„æµ‹å™¨"""
        self.model_path = model_path
        self.processor_path = model_path.replace('.pth', '_processor.pkl')
        self.config_path = model_path.replace('.pth', '_config.pkl')
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs('../../results/predictions', exist_ok=True)
        os.makedirs('../../data/Adjustment_csv', exist_ok=True)
        
        # åŠ è½½æ¨¡å‹ã€å¤„ç†å™¨å’Œé…ç½®
        self.model = None
        self.processor = None
        self.config = None
        
        self.load_model_and_processor()
        
    def load_model_and_processor(self):
        """åŠ è½½æ¨¡å‹ã€æ•°æ®å¤„ç†å™¨å’Œé…ç½®"""
        try:
            # åŠ è½½é…ç½®
            print("ğŸ“‹ æ­£åœ¨åŠ è½½é…ç½®æ–‡ä»¶...")
            if os.path.exists(self.config_path):
                with open(self.config_path, 'rb') as f:
                    self.config = pickle.load(f)
                print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            else:
                print("âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                self.config = {
                    'seq_length': 20,
                    'input_dim': 21,
                    'd_model': 64,
                    'nhead': 8,
                    'num_layers': 2,
                    'dropout': 0.1,
                    'model_type': 'basic'
                }
            
            # åŠ è½½æ•°æ®å¤„ç†å™¨
            print("ğŸ”§ æ­£åœ¨åŠ è½½æ•°æ®å¤„ç†å™¨...")
            if os.path.exists(self.processor_path):
                with open(self.processor_path, 'rb') as f:
                    self.processor = pickle.load(f)
                print("âœ… æ•°æ®å¤„ç†å™¨åŠ è½½æˆåŠŸ")
            else:
                print("âš ï¸  æ•°æ®å¤„ç†å™¨ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„å¤„ç†å™¨")
                if self.config is not None:
                    self.processor = StockDataProcessor(seq_length=self.config['seq_length'])
                else:
                    self.processor = StockDataProcessor(seq_length=20)
            
            # åˆ›å»ºæ¨¡å‹
            print("ğŸ—ï¸  æ­£åœ¨åˆ›å»ºæ¨¡å‹...")
            if self.config is None:
                print("âŒ é…ç½®ä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºæ¨¡å‹")
                return
                
            model_type = self.config.get('model_type', 'basic')
            
            if model_type == 'basic':
                self.model = StockTransformer(
                    input_dim=self.config['input_dim'],
                    d_model=self.config['d_model'],
                    nhead=self.config['nhead'],
                    num_layers=self.config['num_layers'],
                    seq_len=self.config['seq_length'],
                    output_dim=1,
                    dropout=self.config['dropout']
                )
            elif model_type == 'advanced':
                self.model = AdvancedStockTransformer(
                    input_dim=self.config['input_dim'],
                    d_model=self.config['d_model'],
                    nhead=self.config['nhead'],
                    num_layers=self.config['num_layers'],
                    seq_len=self.config['seq_length'],
                    output_dim=1,
                    dropout=self.config['dropout']
                )
            
            if self.model is not None:
                self.model = self.model.to(self.device)
                print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
                
                # åŠ è½½æ¨¡å‹æƒé‡
                print("ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹æƒé‡...")
                if os.path.exists(self.model_path):
                    state_dict = torch.load(self.model_path, map_location=self.device)
                    self.model.load_state_dict(state_dict)
                    self.model.eval()
                    print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
                else:
                    raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            else:
                raise ValueError("æ¨¡å‹åˆ›å»ºå¤±è´¥")
                
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
            raise
    
    def prepare_single_stock_data(self, stock_data, target_col='close'):
        """
        å‡†å¤‡å•åªè‚¡ç¥¨çš„æ•°æ®ç”¨äºé¢„æµ‹
        è¿™æ˜¯ä¿®å¤ç¼ºå¤±æ–¹æ³•çš„å…³é”®å‡½æ•°
        """
        try:
            # æ£€æŸ¥é…ç½®æ˜¯å¦å­˜åœ¨
            if self.config is None:
                print("âŒ é…ç½®ä¸ºç©ºï¼Œæ— æ³•å‡†å¤‡æ•°æ®")
                return None, None
                
            # æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿ
            if len(stock_data) < self.config['seq_length']:
                print(f"âŒ æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {self.config['seq_length']} æ¡è®°å½•")
                return None, None
            
            # å‡†å¤‡ç‰¹å¾åˆ—
            feature_cols = ['open', 'high', 'low', 'close', 'volume']
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            missing_cols = [col for col in feature_cols if col not in stock_data.columns]
            if missing_cols:
                print(f"âŒ ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}")
                return None, None
            
            # åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡
            data_with_indicators = self.create_technical_indicators(stock_data.copy())
            
            # é€‰æ‹©ç‰¹å¾åˆ— - ç¡®ä¿ç»´åº¦åŒ¹é…æ¨¡å‹é…ç½®
            feature_columns = [
                'open', 'high', 'low', 'close', 'volume',
                'ma_5', 'ma_10', 'ma_20', 'ma_50',
                'ema_12', 'ema_26',
                'rsi', 'macd', 'macd_signal', 'macd_histogram',
                'bb_upper', 'bb_middle', 'bb_lower',
                'price_change', 'volume_change',
                'volatility'  # ç§»é™¤ 'price_position' ä»¥åŒ¹é…21ç»´
            ]
            
            # æ£€æŸ¥ç‰¹å¾åˆ—æ˜¯å¦å­˜åœ¨
            available_features = [col for col in feature_columns if col in data_with_indicators.columns]
            if len(available_features) < 5:
                print(f"âš ï¸  å¯ç”¨ç‰¹å¾è¾ƒå°‘: {len(available_features)}")
                # ä½¿ç”¨åŸºç¡€ç‰¹å¾
                available_features = ['open', 'high', 'low', 'close', 'volume']
            
            # æå–ç‰¹å¾æ•°æ®
            feature_data = data_with_indicators[available_features].copy()
            
            # æ•°æ®æ ‡å‡†åŒ–
            if self.processor is None or not hasattr(self.processor, 'scalers') or self.processor.scalers is None:
                print("âš ï¸  ç¼ºå°‘é¢„è®­ç»ƒçš„æ ‡å‡†åŒ–å™¨ï¼Œåˆ›å»ºæ–°çš„æ ‡å‡†åŒ–å™¨")
                if self.processor is None:
                    if self.config is not None:
                        self.processor = StockDataProcessor(seq_length=self.config['seq_length'])
                    else:
                        self.processor = StockDataProcessor(seq_length=20)
                self.processor.scalers = {}
                for col in feature_data.columns:
                    scaler = MinMaxScaler()
                    feature_data[col] = scaler.fit_transform(feature_data[col].values.reshape(-1, 1)).flatten()
                    self.processor.scalers[col] = scaler
            else:
                # ä½¿ç”¨å·²æœ‰çš„æ ‡å‡†åŒ–å™¨
                for col in feature_data.columns:
                    if col in self.processor.scalers:
                        feature_data[col] = self.processor.scalers[col].transform(feature_data[col].values.reshape(-1, 1)).flatten()
                    else:
                        # å¦‚æœæ²¡æœ‰å¯¹åº”çš„æ ‡å‡†åŒ–å™¨ï¼Œåˆ›å»ºæ–°çš„
                        scaler = MinMaxScaler()
                        feature_data[col] = scaler.fit_transform(feature_data[col].values.reshape(-1, 1)).flatten()
                        self.processor.scalers[col] = scaler
            
            # åˆ›å»ºåºåˆ—æ•°æ®
            X, y = [], []
            seq_length = self.config['seq_length']
            
            for i in range(seq_length, len(feature_data)):
                X.append(feature_data.iloc[i-seq_length:i].values)
                y.append(feature_data[target_col].iloc[i])
            
            X = np.array(X)
            y = np.array(y) if len(y) > 0 else None
            
            print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ: X.shape={X.shape}, y.shape={y.shape if y is not None else 'None'}")
            
            return X, y
            
        except Exception as e:
            print(f"âŒ å‡†å¤‡æ•°æ®æ—¶å‡ºé”™: {e}")
            return None, None
    
    def create_technical_indicators(self, data):
        """åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡"""
        try:
            # ç§»åŠ¨å¹³å‡çº¿
            data['ma_5'] = data['close'].rolling(window=5).mean()
            data['ma_10'] = data['close'].rolling(window=10).mean()
            data['ma_20'] = data['close'].rolling(window=20).mean()
            data['ma_50'] = data['close'].rolling(window=50).mean()
            
            # æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿
            data['ema_12'] = data['close'].ewm(span=12).mean()
            data['ema_26'] = data['close'].ewm(span=26).mean()
            
            # RSI
            delta = data['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            data['rsi'] = 100 - (100 / (1 + rs))
            
            # MACD
            data['macd'] = data['ema_12'] - data['ema_26']
            data['macd_signal'] = data['macd'].ewm(span=9).mean()
            data['macd_histogram'] = data['macd'] - data['macd_signal']
            
            # å¸ƒæ—å¸¦
            data['bb_middle'] = data['close'].rolling(window=20).mean()
            bb_std = data['close'].rolling(window=20).std()
            data['bb_upper'] = data['bb_middle'] + (bb_std * 2)
            data['bb_lower'] = data['bb_middle'] - (bb_std * 2)
            
            # ä»·æ ¼å˜åŒ–
            data['price_change'] = data['close'].pct_change()
            data['volume_change'] = data['volume'].pct_change()
            
            # æ³¢åŠ¨ç‡
            data['volatility'] = data['close'].rolling(window=20).std()
            
            # ä»·æ ¼ä½ç½®
            high_20 = data['high'].rolling(window=20).max()
            low_20 = data['low'].rolling(window=20).min()
            data['price_position'] = (data['close'] - low_20) / (high_20 - low_20)
            
            # å¡«å……ç¼ºå¤±å€¼
            data = data.fillna(method='ffill').fillna(method='bfill')
            
            # å¤„ç†æ— ç©·å¤§å€¼
            data = data.replace([np.inf, -np.inf], np.nan)
            data = data.fillna(method='ffill').fillna(method='bfill')
            
            # å¦‚æœè¿˜æœ‰æ— ç©·å¤§å€¼ï¼Œç”¨0å¡«å……
            data = data.replace([np.inf, -np.inf], 0)
            
            return data
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            return data
    
    def load_all_stock_data_from_daily_files(self, data_path="../../data/test_csv"):
        """ä»æ¯æ—¥æ•°æ®æ–‡ä»¶ä¸­åŠ è½½æ‰€æœ‰è‚¡ç¥¨çš„å†å²æ•°æ®"""
        print(f"ğŸ“‚ æ­£åœ¨ä»æ¯æ—¥æ•°æ®æ–‡ä»¶ä¸­åŠ è½½è‚¡ç¥¨å†å²æ•°æ®: {data_path}")
        
        try:
            if not os.path.exists(data_path):
                print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")
                return None
            
            # è·å–æ‰€æœ‰CSVæ–‡ä»¶å¹¶æŒ‰æ—¥æœŸæ’åº
            csv_files = [f for f in os.listdir(data_path) if f.endswith('.csv')]
            csv_files.sort()  # æŒ‰æ–‡ä»¶åæ’åºï¼ˆæ—¥æœŸï¼‰
            
            print(f"ğŸ“… æ‰¾åˆ° {len(csv_files)} ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®æ–‡ä»¶")
            
            # ç”¨äºå­˜å‚¨æ¯åªè‚¡ç¥¨çš„å†å²æ•°æ®
            stock_history = {}
            
            # éå†æ¯ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®æ–‡ä»¶
            for filename in csv_files:
                file_path = os.path.join(data_path, filename)
                trading_date = filename.replace('_daily.csv', '')
                
                try:
                    # è¯»å–å½“æ—¥æ•°æ®
                    daily_data = pd.read_csv(file_path)
                    
                    # å¤„ç†åˆ—åå·®å¼‚
                    column_mapping = {}
                    if 'vol' in daily_data.columns and 'volume' not in daily_data.columns:
                        column_mapping['vol'] = 'volume'
                    if 'tradingday' in daily_data.columns and 'date' not in daily_data.columns:
                        column_mapping['tradingday'] = 'date'
                    
                    # é‡å‘½ååˆ—
                    if column_mapping:
                        daily_data = daily_data.rename(columns=column_mapping)
                    
                    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
                    required_cols = ['open', 'high', 'low', 'close', 'volume', 'secucode']
                    if not all(col in daily_data.columns for col in required_cols):
                        missing_cols = [col for col in required_cols if col not in daily_data.columns]
                        print(f"âš ï¸  è·³è¿‡æ–‡ä»¶ {filename}: ç¼ºå°‘å¿…è¦åˆ— {missing_cols}")
                        continue
                    
                    # ä¸ºæ¯åªè‚¡ç¥¨æ·»åŠ å½“æ—¥æ•°æ®
                    for _, row in daily_data.iterrows():
                        stock_code = row['secucode']
                        
                        if stock_code not in stock_history:
                            stock_history[stock_code] = []
                        
                        # æ·»åŠ å½“æ—¥æ•°æ®
                        stock_history[stock_code].append({
                            'date': trading_date,
                            'open': row['open'],
                            'high': row['high'],
                            'low': row['low'],
                            'close': row['close'],
                            'volume': row['volume'],
                            'preclose': row.get('preclose', row['close']),
                            'amount': row.get('amount', 0),
                            'deals': row.get('deals', 0)
                        })
                        
                except Exception as e:
                    print(f"âŒ å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
                    continue
            
            # å°†æ¯åªè‚¡ç¥¨çš„æ•°æ®è½¬æ¢ä¸ºDataFrame
            stock_data = {}
            for stock_code, history in stock_history.items():
                if len(history) >= 20:  # è‡³å°‘éœ€è¦20å¤©çš„æ•°æ®
                    df = pd.DataFrame(history)
                    df = df.sort_values('date')  # æŒ‰æ—¥æœŸæ’åº
                    stock_data[stock_code] = df
                    print(f"âœ… è‚¡ç¥¨ {stock_code}: {len(df)} ä¸ªäº¤æ˜“æ—¥æ•°æ®")
            
            print(f"âœ… æˆåŠŸåŠ è½½ {len(stock_data)} åªè‚¡ç¥¨çš„å†å²æ•°æ®")
            return stock_data
            
        except Exception as e:
            print(f"âŒ åŠ è½½è‚¡ç¥¨å†å²æ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def predict_single_stock_july_first(self, stock_data, stock_code):
        """é¢„æµ‹å•åªè‚¡ç¥¨7æœˆ1å·çš„ä»·æ ¼"""
        try:
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
            if self.model is None:
                print(f"âŒ æ¨¡å‹ä¸ºç©ºï¼Œæ— æ³•é¢„æµ‹è‚¡ç¥¨ {stock_code}")
                return None
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿ
            if stock_data is None or self.config is None or len(stock_data) < self.config['seq_length']:
                required_length = self.config['seq_length'] if self.config is not None else 20
                print(f"âŒ è‚¡ç¥¨ {stock_code} æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {required_length} æ¡è®°å½•")
                return None
            
            # å‡†å¤‡æ•°æ®
            X, _ = self.prepare_single_stock_data(stock_data, target_col='close')
            
            if X is None or len(X) == 0:
                print(f"âŒ è‚¡ç¥¨ {stock_code} æ•°æ®å‡†å¤‡å¤±è´¥")
                return None
            
            # ä½¿ç”¨æœ€åä¸€ä¸ªåºåˆ—è¿›è¡Œé¢„æµ‹
            last_sequence = X[-1]
            
            # è¿›è¡Œé¢„æµ‹
            self.model.eval()
            with torch.no_grad():
                X_tensor = torch.FloatTensor(last_sequence).unsqueeze(0).to(self.device)
                prediction = self.model(X_tensor).cpu().numpy().flatten()[0]
            
            # åæ ‡å‡†åŒ–é¢„æµ‹ç»“æœ
            if self.processor is not None and hasattr(self.processor, 'scalers') and 'close' in self.processor.scalers:
                prediction = self.processor.scalers['close'].inverse_transform(
                    np.array([prediction]).reshape(-1, 1)
                )[0, 0]
            
            # è·å–æœ€åä¸€å¤©çš„å®é™…æ•°æ®
            if len(stock_data) == 0:
                print(f"âŒ è‚¡ç¥¨ {stock_code} æ•°æ®ä¸ºç©º")
                return None
            last_day_data = stock_data.iloc[-1]
            
            # æ„é€ é¢„æµ‹ç»“æœ
            result = {
                'stock_code': stock_code,
                'last_close': last_day_data['close'],
                'predicted_close': prediction,
                'predicted_open': prediction * 0.995,  # ä¼°ç®—å¼€ç›˜ä»·
                'predicted_high': prediction * 1.01,   # ä¼°ç®—æœ€é«˜ä»·
                'predicted_low': prediction * 0.99,    # ä¼°ç®—æœ€ä½ä»·
                'predicted_volume': last_day_data['volume'],  # ä½¿ç”¨å†å²æˆäº¤é‡
                'last_trading_day': last_day_data['date'],
                'data_points': len(stock_data)
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
            return None
    
    def predict_all_stocks_july_first(self, data_path="../../data/test_csv"):
        """é¢„æµ‹æ‰€æœ‰è‚¡ç¥¨7æœˆ1å·çš„ä»·æ ¼"""
        print("ğŸ¯ å¼€å§‹é¢„æµ‹æ‰€æœ‰è‚¡ç¥¨7æœˆ1å·çš„ä»·æ ¼...")
        
        # åŠ è½½æ‰€æœ‰è‚¡ç¥¨çš„å†å²æ•°æ®
        stock_data = self.load_all_stock_data_from_daily_files(data_path)
        if stock_data is None:
            print("âŒ æ— æ³•åŠ è½½è‚¡ç¥¨å†å²æ•°æ®")
            return None
        
        # é¢„æµ‹æ¯åªè‚¡ç¥¨
        predictions = {}
        total_stocks = len(stock_data)
        successful_predictions = 0
        
        print(f"\nğŸ“Š å¼€å§‹é¢„æµ‹ {total_stocks} åªè‚¡ç¥¨...")
        
        for i, (stock_code, data) in enumerate(stock_data.items(), 1):
            print(f"\nğŸ”® [{i}/{total_stocks}] é¢„æµ‹ {stock_code} çš„7æœˆ1å·ä»·æ ¼...")
            
            result = self.predict_single_stock_july_first(data, stock_code)
            if result:
                predictions[stock_code] = result
                successful_predictions += 1
                print(f"âœ… {stock_code}: é¢„æµ‹æ”¶ç›˜ä»· {result['predicted_close']:.4f} (åŸºäº {result['data_points']} å¤©æ•°æ®)")
            else:
                print(f"âŒ {stock_code}: é¢„æµ‹å¤±è´¥")
        
        print(f"\nâœ… å®Œæˆé¢„æµ‹ï¼ŒæˆåŠŸé¢„æµ‹ {successful_predictions}/{total_stocks} åªè‚¡ç¥¨")
        return predictions
    
    def save_july_first_predictions_to_csv(self, predictions, output_path="../../data/Adjustment_csv/7æœˆ1é¢„æµ‹.csv"):
        """ä¿å­˜7æœˆ1å·é¢„æµ‹ç»“æœåˆ°CSVæ–‡ä»¶"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜7æœˆ1å·é¢„æµ‹ç»“æœåˆ°CSVæ–‡ä»¶...")
        
        try:
            # åˆ›å»ºé¢„æµ‹æ•°æ®åˆ—è¡¨
            prediction_data = []
            
            for stock_code, result in predictions.items():
                row = {
                    'tradingday': '20250701',
                    'secucode': stock_code,
                    'preclose': result['last_close'],
                    'open': result['predicted_open'],
                    'high': result['predicted_high'],
                    'low': result['predicted_low'],
                    'close': result['predicted_close'],
                    'vol': result['predicted_volume'],  # ä½¿ç”¨ 'vol' è€Œä¸æ˜¯ 'volume'
                    'amount': result['predicted_volume'] * result['predicted_close'],
                    'deals': 0  # æ— æ³•é¢„æµ‹æˆäº¤ç¬”æ•°
                }
                prediction_data.append(row)
            
            # è½¬æ¢ä¸ºDataFrameå¹¶ä¿å­˜
            df = pd.DataFrame(prediction_data)
            df.to_csv(output_path, index=False, encoding='utf-8')
            
            print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
            print(f"ğŸ“Š å…±é¢„æµ‹ {len(prediction_data)} åªè‚¡ç¥¨")
            
            return output_path
            
        except Exception as e:
            print(f"âŒ ä¿å­˜é¢„æµ‹ç»“æœæ—¶å‡ºé”™: {e}")
            return None
    
    def load_actual_july_first_data(self, actual_data_path="../../data/Adjustment_csv/20250701_daily.csv"):
        """åŠ è½½7æœˆ1å·çš„å®é™…æ•°æ®"""
        print(f"ğŸ“‚ æ­£åœ¨åŠ è½½å®é™…æ•°æ®: {actual_data_path}")
        
        try:
            if not os.path.exists(actual_data_path):
                print(f"âŒ å®é™…æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {actual_data_path}")
                return None
            
            actual_data = pd.read_csv(actual_data_path)
            
            # å¤„ç†åˆ—åå·®å¼‚
            column_mapping = {}
            if 'vol' in actual_data.columns and 'volume' not in actual_data.columns:
                column_mapping['vol'] = 'volume'
            if 'tradingday' in actual_data.columns and 'date' not in actual_data.columns:
                column_mapping['tradingday'] = 'date'
            
            # é‡å‘½ååˆ—
            if column_mapping:
                actual_data = actual_data.rename(columns=column_mapping)
            
            print(f"âœ… æˆåŠŸåŠ è½½å®é™…æ•°æ®ï¼Œå…± {len(actual_data)} æ¡è®°å½•")
            
            return actual_data
            
        except Exception as e:
            print(f"âŒ åŠ è½½å®é™…æ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def compare_predictions_with_actual(self, predictions, actual_data):
        """æ¯”è¾ƒé¢„æµ‹ç»“æœä¸å®é™…æ•°æ®"""
        print("ğŸ“Š æ­£åœ¨æ¯”è¾ƒé¢„æµ‹ç»“æœä¸å®é™…æ•°æ®...")
        
        if actual_data is None:
            print("âŒ æ— å®é™…æ•°æ®å¯æ¯”è¾ƒ")
            return None
        
        # åˆ›å»ºæ¯”è¾ƒç»“æœåˆ—è¡¨
        comparison_results = []
        
        # å°†å®é™…æ•°æ®è½¬æ¢ä¸ºå­—å…¸ä»¥ä¾¿æŸ¥æ‰¾
        actual_dict = {}
        for _, row in actual_data.iterrows():
            actual_dict[row['secucode']] = row
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        total_predictions = 0
        correct_direction = 0
        total_abs_error = 0
        total_rel_error = 0
        
        for stock_code, prediction in predictions.items():
            if stock_code in actual_dict:
                actual_row = actual_dict[stock_code]
                
                # è®¡ç®—è¯¯å·®
                predicted_close = prediction['predicted_close']
                actual_close = actual_row['close']
                last_close = prediction['last_close']
                
                abs_error = abs(predicted_close - actual_close)
                rel_error = abs_error / actual_close * 100
                
                # è®¡ç®—æ–¹å‘å‡†ç¡®æ€§
                predicted_direction = "ä¸Šæ¶¨" if predicted_close > last_close else "ä¸‹è·Œ"
                actual_direction = "ä¸Šæ¶¨" if actual_close > actual_row['preclose'] else "ä¸‹è·Œ"
                direction_correct = predicted_direction == actual_direction
                
                if direction_correct:
                    correct_direction += 1
                
                total_predictions += 1
                total_abs_error += abs_error
                total_rel_error += rel_error
                
                # è®°å½•æ¯”è¾ƒç»“æœ
                comparison_result = {
                    'stock_code': stock_code,
                    'predicted_close': predicted_close,
                    'actual_close': actual_close,
                    'last_close': last_close,
                    'abs_error': abs_error,
                    'rel_error': rel_error,
                    'predicted_direction': predicted_direction,
                    'actual_direction': actual_direction,
                    'direction_correct': direction_correct
                }
                comparison_results.append(comparison_result)
            else:
                print(f"âš ï¸  è‚¡ç¥¨ {stock_code} åœ¨å®é™…æ•°æ®ä¸­ä¸å­˜åœ¨")
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        if total_predictions > 0:
            direction_accuracy = correct_direction / total_predictions
            avg_abs_error = total_abs_error / total_predictions
            avg_rel_error = total_rel_error / total_predictions
            
            summary = {
                'total_stocks': total_predictions,
                'direction_accuracy': direction_accuracy,
                'avg_abs_error': avg_abs_error,
                'avg_rel_error': avg_rel_error,
                'correct_direction_count': correct_direction
            }
            
            print(f"âœ… æ¯”è¾ƒå®Œæˆ:")
            print(f"   æ€»è‚¡ç¥¨æ•°: {total_predictions}")
            print(f"   æ–¹å‘å‡†ç¡®ç‡: {direction_accuracy:.2%}")
            print(f"   å¹³å‡ç»å¯¹è¯¯å·®: {avg_abs_error:.4f}")
            print(f"   å¹³å‡ç›¸å¯¹è¯¯å·®: {avg_rel_error:.2f}%")
            
            return {
                'comparison_results': comparison_results,
                'summary': summary
            }
        else:
            print("âŒ æ²¡æœ‰å¯æ¯”è¾ƒçš„æ•°æ®")
            return None
    
    def generate_comparison_report(self, comparison_data, output_path="../../data/Adjustment_csv/7æœˆ1é¢„æµ‹.txt"):
        """ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š"""
        print("ğŸ“ æ­£åœ¨ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š...")
        
        try:
            if comparison_data is None:
                print("âŒ æ— æ¯”è¾ƒæ•°æ®å¯ç”ŸæˆæŠ¥å‘Š")
                return None
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("=== 7æœˆ1æ—¥è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç»“æœæŠ¥å‘Š ===\n\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                # å†™å…¥æ€»ä½“ç»Ÿè®¡
                summary = comparison_data['summary']
                f.write("=== æ€»ä½“ç»Ÿè®¡ ===\n")
                f.write(f"é¢„æµ‹è‚¡ç¥¨æ€»æ•°: {summary['total_stocks']}\n")
                f.write(f"æ–¹å‘é¢„æµ‹å‡†ç¡®ç‡: {summary['direction_accuracy']:.2%}\n")
                f.write(f"æ–¹å‘é¢„æµ‹æ­£ç¡®æ•°é‡: {summary['correct_direction_count']}\n")
                f.write(f"å¹³å‡ç»å¯¹è¯¯å·®: {summary['avg_abs_error']:.4f}\n")
                f.write(f"å¹³å‡ç›¸å¯¹è¯¯å·®: {summary['avg_rel_error']:.2f}%\n\n")
                
                # å†™å…¥è¯¦ç»†ç»“æœ
                f.write("=== è¯¦ç»†é¢„æµ‹ç»“æœ ===\n")
                f.write("è‚¡ç¥¨ä»£ç \té¢„æµ‹æ”¶ç›˜ä»·\tå®é™…æ”¶ç›˜ä»·\tç»å¯¹è¯¯å·®\tç›¸å¯¹è¯¯å·®\tæ–¹å‘é¢„æµ‹\tå®é™…æ–¹å‘\tæ–¹å‘æ­£ç¡®\n")
                
                for result in comparison_data['comparison_results']:
                    f.write(f"{result['stock_code']}\t"
                           f"{result['predicted_close']:.4f}\t"
                           f"{result['actual_close']:.4f}\t"
                           f"{result['abs_error']:.4f}\t"
                           f"{result['rel_error']:.2f}%\t"
                           f"{result['predicted_direction']}\t"
                           f"{result['actual_direction']}\t"
                           f"{'âœ“' if result['direction_correct'] else 'âœ—'}\n")
                
                # å†™å…¥æ¨¡å‹ä¿¡æ¯
                f.write("\n=== æ¨¡å‹ä¿¡æ¯ ===\n")
                f.write(f"æ¨¡å‹è·¯å¾„: {self.model_path}\n")
                if self.config is not None:
                    f.write(f"æ¨¡å‹ç±»å‹: {self.config.get('model_type', 'basic')}\n")
                    f.write(f"åºåˆ—é•¿åº¦: {self.config['seq_length']}\n")
                    f.write(f"è¾“å…¥ç»´åº¦: {self.config['input_dim']}\n")
                    f.write(f"æ¨¡å‹ç»´åº¦: {self.config['d_model']}\n")
                    f.write(f"æ³¨æ„åŠ›å¤´æ•°: {self.config['nhead']}\n")
                    f.write(f"å±‚æ•°: {self.config['num_layers']}\n")
                    f.write(f"Dropout: {self.config['dropout']}\n")
                else:
                    f.write("æ¨¡å‹é…ç½®: æœªåŠ è½½\n")
                
                # å†™å…¥æ€§èƒ½è¯„ä¼°
                f.write("\n=== æ€§èƒ½è¯„ä¼° ===\n")
                if summary['avg_rel_error'] < 5:
                    f.write("é¢„æµ‹ç²¾åº¦: ä¼˜ç§€ (ç›¸å¯¹è¯¯å·® < 5%)\n")
                elif summary['avg_rel_error'] < 10:
                    f.write("é¢„æµ‹ç²¾åº¦: è‰¯å¥½ (ç›¸å¯¹è¯¯å·® < 10%)\n")
                elif summary['avg_rel_error'] < 20:
                    f.write("é¢„æµ‹ç²¾åº¦: ä¸€èˆ¬ (ç›¸å¯¹è¯¯å·® < 20%)\n")
                else:
                    f.write("é¢„æµ‹ç²¾åº¦: éœ€è¦æ”¹è¿› (ç›¸å¯¹è¯¯å·® >= 20%)\n")
                
                if summary['direction_accuracy'] > 0.6:
                    f.write("æ–¹å‘é¢„æµ‹: è‰¯å¥½ (å‡†ç¡®ç‡ > 60%)\n")
                elif summary['direction_accuracy'] > 0.5:
                    f.write("æ–¹å‘é¢„æµ‹: ä¸€èˆ¬ (å‡†ç¡®ç‡ > 50%)\n")
                else:
                    f.write("æ–¹å‘é¢„æµ‹: éœ€è¦æ”¹è¿› (å‡†ç¡®ç‡ <= 50%)\n")
            
            print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")
            return None
    
    def run_july_first_prediction(self, 
                                 data_path="../../data/test_csv",
                                 actual_data_path="../../data/Adjustment_csv/20250701_daily.csv"):
        """è¿è¡Œå®Œæ•´çš„7æœˆ1å·é¢„æµ‹æµç¨‹"""
        print("ğŸš€ å¼€å§‹è¿è¡Œ7æœˆ1å·é¢„æµ‹æµç¨‹...")
        
        try:
            # 1. é¢„æµ‹æ‰€æœ‰è‚¡ç¥¨7æœˆ1å·çš„ä»·æ ¼
            predictions = self.predict_all_stocks_july_first(data_path)
            if predictions is None:
                print("âŒ é¢„æµ‹å¤±è´¥")
                return False
            
            # 2. ä¿å­˜é¢„æµ‹ç»“æœåˆ°CSV
            prediction_csv_path = self.save_july_first_predictions_to_csv(predictions)
            if prediction_csv_path is None:
                print("âŒ ä¿å­˜é¢„æµ‹ç»“æœå¤±è´¥")
                return False
            
            # 3. åŠ è½½å®é™…æ•°æ®
            actual_data = self.load_actual_july_first_data(actual_data_path)
            
            # 4. æ¯”è¾ƒé¢„æµ‹ç»“æœä¸å®é™…æ•°æ®
            comparison_data = self.compare_predictions_with_actual(predictions, actual_data)
            
            # 5. ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š
            report_path = self.generate_comparison_report(comparison_data)
            
            if report_path:
                print("âœ… 7æœˆ1å·é¢„æµ‹æµç¨‹å®Œæˆ!")
                print(f"ğŸ“„ é¢„æµ‹æ•°æ®æ–‡ä»¶: {prediction_csv_path}")
                print(f"ğŸ“„ å¯¹æ¯”æŠ¥å‘Šæ–‡ä»¶: {report_path}")
                return True
            else:
                print("âš ï¸  é¢„æµ‹å®Œæˆä½†æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ è¿è¡Œé¢„æµ‹æµç¨‹æ—¶å‡ºé”™: {e}")
            return False

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("=" * 60)
    print("ğŸš€ è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç¨‹åºå¯åŠ¨")
    print("=" * 60)
    
    try:
        # è®¾ç½®è·¯å¾„
        model_path = "../../models/best_model.pth"
        data_path = "../../data/test_csv"
        actual_data_path = "../../data/Adjustment_csv/20250701_daily.csv"
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²è®­ç»ƒå¹¶ä¿å­˜åœ¨æ­£ç¡®ä½ç½®")
            return False
        
        # æ£€æŸ¥æµ‹è¯•æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(data_path):
            print(f"âŒ æµ‹è¯•æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_path}")
            print("è¯·ç¡®ä¿æµ‹è¯•æ•°æ®ç›®å½•å­˜åœ¨ä¸”åŒ…å«è‚¡ç¥¨æ•°æ®æ–‡ä»¶")
            return False
        
        # åˆ›å»ºé¢„æµ‹å™¨
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–é¢„æµ‹å™¨...")
        predictor = StockPredictor(model_path=model_path)
        
        # è¿è¡Œ7æœˆ1å·é¢„æµ‹æµç¨‹
        success = predictor.run_july_first_prediction(
            data_path=data_path,
            actual_data_path=actual_data_path
        )
        
        if success:
            print("\n" + "=" * 60)
            print("âœ… é¢„æµ‹ç¨‹åºæ‰§è¡ŒæˆåŠŸ!")
            print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
            print("   - é¢„æµ‹æ•°æ®: ../../data/Adjustment_csv/7æœˆ1é¢„æµ‹.csv")
            print("   - å¯¹æ¯”æŠ¥å‘Š: ../../data/Adjustment_csv/7æœˆ1é¢„æµ‹.txt")
            print("=" * 60)
            return True
        else:
            print("\n" + "=" * 60)
            print("âŒ é¢„æµ‹ç¨‹åºæ‰§è¡Œå¤±è´¥!")
            print("=" * 60)
            return False
            
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    # è¿è¡Œä¸»ç¨‹åº
    success = main()
    
    if success:
        print("\nğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆï¼Œè¯·æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶!")
    else:
        print("\nğŸ’¡ ç¨‹åºæ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹:")
        print("   1. æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶ä¸”è·¯å¾„æ­£ç¡®")
        print("   2. æµ‹è¯•æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨å¹¶åŒ…å«CSVæ–‡ä»¶")
        print("   3. æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®(åŒ…å«open,high,low,close,volumeåˆ—)")
        print("   4. æ¨¡å‹é…ç½®æ–‡ä»¶æ˜¯å¦åŒ¹é…")
        
    input("\næŒ‰ä»»æ„é”®é€€å‡º...")