"""
è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç¨‹åº - æ”¹è¿›ç‰ˆå¤šä»»åŠ¡å­¦ä¹ æ¨¡å‹é¢„æµ‹å™¨
==========================================

åŠŸèƒ½ï¼š
1. åŠ è½½æ”¹è¿›ç‰ˆå¤šä»»åŠ¡å­¦ä¹ æ¨¡å‹ï¼ˆä»·æ ¼ã€æ–¹å‘ã€å¹…åº¦é¢„æµ‹ï¼‰
2. å¯¹æ–°çš„è‚¡ç¥¨æ•°æ®è¿›è¡Œå¤šä»»åŠ¡é¢„æµ‹
3. å¯è§†åŒ–é¢„æµ‹ç»“æœ
4. è®¡ç®—å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡
5. æ”¯æŒæ‰¹é‡é¢„æµ‹å’Œå•è‚¡ç¥¨é¢„æµ‹

é€‚é…æ¨¡å‹ï¼š
- ImprovedStockTransformer (å¤šä»»åŠ¡å­¦ä¹ )
- MultiTaskLoss (å¤šä»»åŠ¡æŸå¤±å‡½æ•°)
- é«˜çº§ç‰¹å¾å·¥ç¨‹

ä½œè€…ï¼šAI Assistant
åˆ›å»ºæ—¶é—´ï¼š2024å¹´
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import os
import pickle
import warnings
import sys
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import RobustScaler

warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

# å¯¼å…¥æ”¹è¿›ç‰ˆæ¨¡å‹å’Œå¤„ç†å™¨
from learn.train.first import ImprovedStockTransformer, ImprovedStockDataProcessor, MultiTaskLoss

class ImprovedStockPredictor:
    """æ”¹è¿›ç‰ˆè‚¡ç¥¨ä»·æ ¼é¢„æµ‹å™¨ - æ”¯æŒå¤šä»»åŠ¡å­¦ä¹ """
    
    def __init__(self, model_path=None):
        """åˆå§‹åŒ–é¢„æµ‹å™¨"""
        if model_path is None:
            model_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../models/best_improved_model.pth'))
        self.model_path = model_path
        self.config_path = self.model_path.replace('.pth', '_config.pkl')
        self.processor_path = self.model_path.replace('.pth', '_processor.pkl')
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs('../../results/predictions', exist_ok=True)
        os.makedirs('../../data/Adjustment_csv', exist_ok=True)
        
        # åŠ è½½æ¨¡å‹ã€å¤„ç†å™¨å’Œé…ç½®
        self.model = None
        self.processor = None
        self.config = None
        
        self.load_model_and_processor()
        
    def load_model_and_processor(self):
        """åŠ è½½æ¨¡å‹ã€æ•°æ®å¤„ç†å™¨å’Œé…ç½®"""
        try:
            # åŠ è½½é…ç½®
            print("ğŸ“‹ æ­£åœ¨åŠ è½½é…ç½®æ–‡ä»¶...")
            if os.path.exists(self.config_path):
                with open(self.config_path, 'rb') as f:
                    self.config = pickle.load(f)
                print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            else:
                print("âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                self.config = {
                    'seq_length': 60,
                    'd_model': 256,
                    'nhead': 8,
                    'num_layers': 4,
                    'dropout': 0.15,
                    'prediction_days': 7,
                    'batch_size': 64,
                    'learning_rate': 5e-4,
                    'epochs': 150,
                    'weight_decay': 1e-5
                }
            # åŠ è½½æ•°æ®å¤„ç†å™¨
            print("ğŸ”§ æ­£åœ¨åŠ è½½æ•°æ®å¤„ç†å™¨...")
            if os.path.exists(self.processor_path):
                with open(self.processor_path, 'rb') as f:
                    self.processor = pickle.load(f)
                print("âœ… æ•°æ®å¤„ç†å™¨åŠ è½½æˆåŠŸ")
            else:
                print("âš ï¸  æ•°æ®å¤„ç†å™¨ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„å¤„ç†å™¨")
                self.processor = ImprovedStockDataProcessor(
                    seq_length=self.config['seq_length'],
                    prediction_days=self.config['prediction_days']
                )
            # åˆ›å»ºæ¨¡å‹
            print("ğŸ—ï¸  æ­£åœ¨åˆ›å»ºæ¨¡å‹...")
            if self.config is None:
                print("âŒ é…ç½®ä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºæ¨¡å‹")
                return
            # ===== å…³é”®ä¿®æ­£ï¼šinput_dimä¸¥æ ¼ç”¨processor.feature_columnsé•¿åº¦ =====
            input_dim = len(self.processor.feature_columns) if self.processor and hasattr(self.processor, 'feature_columns') and self.processor.feature_columns else self.config.get('input_dim', 50)
            self.model = ImprovedStockTransformer(
                input_dim=input_dim,
                d_model=self.config['d_model'],
                nhead=self.config['nhead'],
                num_layers=self.config['num_layers'],
                seq_len=self.config['seq_length'],
                dropout=self.config['dropout']
            )
            if self.model is not None:
                self.model = self.model.to(self.device)
                print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
                # åŠ è½½æ¨¡å‹æƒé‡
                print("ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹æƒé‡...")
                if os.path.exists(self.model_path):
                    state_dict = torch.load(self.model_path, map_location=self.device)
                    self.model.load_state_dict(state_dict)
                    self.model.eval()
                    print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
                else:
                    raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            else:
                raise ValueError("æ¨¡å‹åˆ›å»ºå¤±è´¥")
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
            raise

    def prepare_prediction_data(self, stock_data):
        """å‡†å¤‡é¢„æµ‹æ•°æ®"""
        try:
            if self.config is None or self.processor is None:
                print("âŒ é…ç½®æˆ–æ•°æ®å¤„ç†å™¨æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
                return None
            # ===== æ–°å¢ï¼šè‡ªåŠ¨å…¼å®¹ vol åˆ—å =====
            if 'vol' not in stock_data.columns:
                for alt in ['volume', 'Volume', 'æˆäº¤é‡']:
                    if alt in stock_data.columns:
                        stock_data['vol'] = stock_data[alt]
                        print(f"âš ï¸ è‡ªåŠ¨å°† {alt} åˆ—é‡å‘½åä¸º vol")
                        break
                else:
                    print(f'âš ï¸ è‚¡ç¥¨æ•°æ®ç¼ºå°‘æˆäº¤é‡(vol)åˆ—ï¼Œå·²ç”¨0å¡«å……ï¼Œé¢„æµ‹ç»“æœå¯èƒ½ä¸å‡†')
                    stock_data['vol'] = 0
            # æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿ
            if len(stock_data) < self.config['seq_length']:
                print(f"âŒ æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {self.config['seq_length']} æ¡è®°å½•")
                return None
            # æ·»åŠ é«˜çº§ç‰¹å¾
            print("ğŸ”§ æ­£åœ¨æ·»åŠ é«˜çº§ç‰¹å¾...")
            data_with_features = self.processor.add_advanced_features(stock_data.copy())
            # ===== å…³é”®ä¿®æ­£ï¼šä¸¥æ ¼ç”¨processor.feature_columnså’Œscalerå¤„ç†ç‰¹å¾ =====
            feature_cols = self.processor.feature_columns
            if not feature_cols:
                print("âŒ å¤„ç†å™¨æœªä¿å­˜ç‰¹å¾åˆ—ï¼Œæ— æ³•é¢„æµ‹")
                return None
            # åªä¿ç•™è®­ç»ƒæ—¶çš„ç‰¹å¾åˆ—
            data_features = data_with_features[feature_cols].copy()
            # ä¸¢å¼ƒNaN
            data_features = data_features.dropna()
            if data_features.empty:
                print("âŒ å¤„ç†åæ— æœ‰æ•ˆç‰¹å¾æ•°æ®")
                return None
            # æ ‡å‡†åŒ–
            features_scaled = self.processor.feature_scaler.transform(data_features)
            # æ„é€ åºåˆ—
            X = []
            for i in range(len(features_scaled) - self.config['seq_length'] + 1):
                X.append(features_scaled[i:i + self.config['seq_length']])
            X = np.array(X)
            if X is None or len(X) == 0:
                print("âŒ åºåˆ—æ•°æ®å‡†å¤‡å¤±è´¥")
                return None
            print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ: X.shape={X.shape}")
            return X
        except Exception as e:
            print(f"âŒ å‡†å¤‡é¢„æµ‹æ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def predict_single_stock(self, stock_data, stock_code):
        """é¢„æµ‹å•åªè‚¡ç¥¨"""
        try:
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
            if self.model is None:
                print(f"âŒ æ¨¡å‹ä¸ºç©ºï¼Œæ— æ³•é¢„æµ‹è‚¡ç¥¨ {stock_code}")
                return None
            
            # å‡†å¤‡æ•°æ®
            X = self.prepare_prediction_data(stock_data)
            if X is None:
                return None
            
            # ä½¿ç”¨æœ€åä¸€ä¸ªåºåˆ—è¿›è¡Œé¢„æµ‹
            last_sequence = X[-1]
            
            # è¿›è¡Œå¤šä»»åŠ¡é¢„æµ‹
            self.model.eval()
            with torch.no_grad():
                X_tensor = torch.FloatTensor(last_sequence).unsqueeze(0).to(self.device)
                price_pred, direction_pred, magnitude_pred = self.model(X_tensor)
                
                # è·å–é¢„æµ‹ç»“æœ
                predicted_price = price_pred.cpu().numpy().flatten()[0]
                predicted_direction = torch.softmax(direction_pred, dim=1).cpu().numpy()[0]
                predicted_magnitude = torch.softmax(magnitude_pred, dim=1).cpu().numpy()[0]
            
            # è·å–æœ€åä¸€å¤©çš„å®é™…æ•°æ®
            last_day_data = stock_data.iloc[-1]
            
            # æ„é€ é¢„æµ‹ç»“æœ
            result = {
                'stock_code': stock_code,
                'last_close': last_day_data['close'],
                'predicted_price': predicted_price,
                'direction_probabilities': predicted_direction,
                'predicted_direction': np.argmax(predicted_direction),  # 0:ä¸‹è·Œ, 1:ä¸Šæ¶¨
                'direction_confidence': np.max(predicted_direction),
                'magnitude_probabilities': predicted_magnitude,
                'predicted_magnitude': np.argmax(predicted_magnitude),  # 0:ä¸‹è·Œ, 1:æ¨ªç›˜, 2:ä¸Šæ¶¨
                'magnitude_confidence': np.max(predicted_magnitude),
                'last_trading_day': last_day_data.get('tradingday', 'unknown'),
                'data_points': len(stock_data),
                'true_direction': int(last_day_data['direction']) if 'direction' in last_day_data else None
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
            return None
    
    def load_stock_data_from_csv(self, data_path="../../data/test_csv"):
        """ä»CSVæ–‡ä»¶åŠ è½½è‚¡ç¥¨æ•°æ®"""
        print(f"ğŸ“‚ æ­£åœ¨ä»CSVæ–‡ä»¶åŠ è½½è‚¡ç¥¨æ•°æ®: {data_path}")
        
        try:
            if self.config is None:
                print("âŒ é…ç½®æœªåŠ è½½ï¼Œæ— æ³•åŠ è½½è‚¡ç¥¨æ•°æ®")
                return None
            if not os.path.exists(data_path):
                print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")
                return None
            
            # è·å–æ‰€æœ‰CSVæ–‡ä»¶
            csv_files = [f for f in os.listdir(data_path) if f.endswith('.csv')]
            csv_files.sort()
            
            print(f"ğŸ“… æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
            
            # ç”¨äºå­˜å‚¨æ¯åªè‚¡ç¥¨çš„æ•°æ®
            stock_data = {}
            
            # éå†æ¯ä¸ªCSVæ–‡ä»¶
            for filename in csv_files:
                file_path = os.path.join(data_path, filename)
                
                try:
                    # è¯»å–æ•°æ®
                    daily_data = pd.read_csv(file_path)
                    
                    # æ£€æŸ¥å¿…è¦çš„åˆ—
                    required_cols = ['secucode', 'close', 'open', 'high', 'low', 'vol']
                    if not all(col in daily_data.columns for col in required_cols):
                        missing_cols = [col for col in required_cols if col not in daily_data.columns]
                        print(f"âš ï¸  è·³è¿‡æ–‡ä»¶ {filename}: ç¼ºå°‘å¿…è¦åˆ— {missing_cols}")
                        continue
                    
                    # é‡å‘½ååˆ—ä»¥åŒ¹é…æœŸæœ›æ ¼å¼
                    column_mapping = {
                        'vol': 'volume',
                        'tradingday': 'date'
                    }
                    daily_data = daily_data.rename(columns=column_mapping)
                    
                    # ä¸ºæ¯åªè‚¡ç¥¨æ·»åŠ æ•°æ®
                    for _, row in daily_data.iterrows():
                        stock_code = row['secucode']
                        
                        if stock_code not in stock_data:
                            stock_data[stock_code] = []
                        
                        # æ·»åŠ æ•°æ®
                        stock_data[stock_code].append({
                            'date': row.get('date', filename.replace('.csv', '')),
                            'open': row['open'],
                            'high': row['high'],
                            'low': row['low'],
                            'close': row['close'],
                            'volume': row['volume'],
                            'preclose': row.get('preclose', row['close']),
                            'amount': row.get('amount', 0),
                            'deals': row.get('deals', 0)
                        })
                        
                except Exception as e:
                    print(f"âŒ å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
                    continue
            
            # å°†æ¯åªè‚¡ç¥¨çš„æ•°æ®è½¬æ¢ä¸ºDataFrame
            processed_data = {}
            for stock_code, history in stock_data.items():
                if self.config is None:
                    print("âŒ é…ç½®æœªåŠ è½½ï¼Œæ— æ³•åˆ¤æ–­åºåˆ—é•¿åº¦")
                    continue
                if len(history) >= self.config['seq_length']:
                    df = pd.DataFrame(history)
                    df = df.sort_values('date')
                    processed_data[stock_code] = df
                    print(f"âœ… è‚¡ç¥¨ {stock_code}: {len(df)} ä¸ªäº¤æ˜“æ—¥æ•°æ®")
            
            print(f"âœ… æˆåŠŸåŠ è½½ {len(processed_data)} åªè‚¡ç¥¨çš„æ•°æ®")
            return processed_data
            
        except Exception as e:
            print(f"âŒ åŠ è½½è‚¡ç¥¨æ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def predict_all_stocks(self, data_path="../../data/test_csv"):
        """é¢„æµ‹æ‰€æœ‰è‚¡ç¥¨"""
        print("ğŸ¯ å¼€å§‹é¢„æµ‹æ‰€æœ‰è‚¡ç¥¨...")
        
        # åŠ è½½è‚¡ç¥¨æ•°æ®
        stock_data = self.load_stock_data_from_csv(data_path)
        if stock_data is None:
            print("âŒ æ— æ³•åŠ è½½è‚¡ç¥¨æ•°æ®")
            return None
        
        # é¢„æµ‹æ¯åªè‚¡ç¥¨
        predictions = {}
        total_stocks = len(stock_data)
        successful_predictions = 0
        
        print(f"\nğŸ“Š å¼€å§‹é¢„æµ‹ {total_stocks} åªè‚¡ç¥¨...")
        
        for i, (stock_code, data) in enumerate(stock_data.items(), 1):
            print(f"\nğŸ”® [{i}/{total_stocks}] é¢„æµ‹ {stock_code}...")
            
            result = self.predict_single_stock(data, stock_code)
            if result:
                predictions[stock_code] = result
                successful_predictions += 1
                
                direction_text = "ä¸Šæ¶¨" if result['predicted_direction'] == 1 else "ä¸‹è·Œ"
                magnitude_text = ["ä¸‹è·Œ", "æ¨ªç›˜", "ä¸Šæ¶¨"][result['predicted_magnitude']]
                
                print(f"âœ… {stock_code}: é¢„æµ‹ä»·æ ¼ {result['predicted_price']:.4f}")
                print(f"   æ–¹å‘: {direction_text} (ç½®ä¿¡åº¦: {result['direction_confidence']:.2%})")
                print(f"   å¹…åº¦: {magnitude_text} (ç½®ä¿¡åº¦: {result['magnitude_confidence']:.2%})")
            else:
                print(f"âŒ {stock_code}: é¢„æµ‹å¤±è´¥")
        
        print(f"\nâœ… å®Œæˆé¢„æµ‹ï¼ŒæˆåŠŸé¢„æµ‹ {successful_predictions}/{total_stocks} åªè‚¡ç¥¨")
        return predictions
    
    def save_predictions_to_csv(self, predictions, output_path="../../data/Adjustment_csv/å¤šä»»åŠ¡é¢„æµ‹ç»“æœ.csv"):
        """ä¿å­˜é¢„æµ‹ç»“æœåˆ°CSVæ–‡ä»¶"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜é¢„æµ‹ç»“æœåˆ°CSVæ–‡ä»¶...")
        
        try:
            # åˆ›å»ºé¢„æµ‹æ•°æ®åˆ—è¡¨
            prediction_data = []
            
            for stock_code, result in predictions.items():
                direction_text = "ä¸Šæ¶¨" if result['predicted_direction'] == 1 else "ä¸‹è·Œ"
                magnitude_text = ["ä¸‹è·Œ", "æ¨ªç›˜", "ä¸Šæ¶¨"][result['predicted_magnitude']]
                
                row = {
                    'stock_code': stock_code,
                    'last_close': result['last_close'],
                    'predicted_price': result['predicted_price'],
                    'predicted_direction': direction_text,
                    'direction_confidence': result['direction_confidence'],
                    'predicted_magnitude': magnitude_text,
                    'magnitude_confidence': result['magnitude_confidence'],
                    'last_trading_day': result['last_trading_day'],
                    'data_points': result['data_points']
                }
                prediction_data.append(row)
            
            # è½¬æ¢ä¸ºDataFrameå¹¶ä¿å­˜
            df = pd.DataFrame(prediction_data)
            df.to_csv(output_path, index=False, encoding='utf-8')
            
            print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
            print(f"ğŸ“Š å…±é¢„æµ‹ {len(prediction_data)} åªè‚¡ç¥¨")
            
            return output_path
            
        except Exception as e:
            print(f"âŒ ä¿å­˜é¢„æµ‹ç»“æœæ—¶å‡ºé”™: {e}")
            return None
    
    def generate_prediction_report(self, predictions, output_path="../../data/Adjustment_csv/å¤šä»»åŠ¡é¢„æµ‹æŠ¥å‘Š.txt"):
        """ç”Ÿæˆé¢„æµ‹æŠ¥å‘Šï¼Œç»Ÿè®¡æ–¹å‘é¢„æµ‹å‡†ç¡®ç‡ï¼ˆä¸20250701_daily.csvçœŸå®directionå¯¹æ¯”ï¼‰"""
        print("ğŸ“ æ­£åœ¨ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š...")
        try:
            # è¯»å–çœŸå®æ ‡ç­¾
            real_csv_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../data/Adjustment_csv/20250701_daily.csv'))
            real_df = None
            if os.path.exists(real_csv_path):
                real_df = pd.read_csv(real_csv_path)
                real_direction_dict = {str(row['secucode']): int(row['direction']) for _, row in real_df.iterrows() if 'direction' in row}
            else:
                real_direction_dict = {}
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("å¤šä»»åŠ¡å­¦ä¹ è‚¡ç¥¨é¢„æµ‹æŠ¥å‘Š\n")
                f.write("="*50 + "\n")
                f.write(f"æ€»é¢„æµ‹è‚¡ç¥¨æ•°: {len(predictions)}\n")
                # ç»Ÿè®¡æ–¹å‘é¢„æµ‹å‡†ç¡®ç‡ï¼ˆä¸csvçœŸå®æ ‡ç­¾å¯¹æ¯”ï¼‰
                y_true = []
                y_pred = []
                for stock_code, result in predictions.items():
                    code = str(stock_code)
                    if code in real_direction_dict:
                        y_true.append(real_direction_dict[code])
                        y_pred.append(result['predicted_direction'])
                if y_true and y_pred:
                    from sklearn.metrics import accuracy_score
                    acc = accuracy_score(y_true, y_pred)
                    f.write(f"ä¸20250701_daily.csvçœŸå®æ ‡ç­¾å¯¹æ¯”çš„æ–¹å‘é¢„æµ‹äºŒåˆ†ç±»å‡†ç¡®ç‡: {acc:.4f}\n")
                    print(f"ğŸ¯ ä¸20250701_daily.csvçœŸå®æ ‡ç­¾å¯¹æ¯”çš„æ–¹å‘é¢„æµ‹äºŒåˆ†ç±»å‡†ç¡®ç‡: {acc:.4f}")
                else:
                    f.write("æœªæ‰¾åˆ°çœŸå®æ ‡ç­¾ï¼Œæ— æ³•ç»Ÿè®¡å‡†ç¡®ç‡\n")
                    print("âš ï¸ æœªæ‰¾åˆ°çœŸå®æ ‡ç­¾ï¼Œæ— æ³•ç»Ÿè®¡å‡†ç¡®ç‡")
                # æ€»ä½“ç»Ÿè®¡
                total_stocks = len(predictions)
                up_count = sum(1 for p in predictions.values() if p['predicted_direction'] == 1)
                down_count = total_stocks - up_count
                
                avg_direction_confidence = np.mean([p['direction_confidence'] for p in predictions.values()])
                avg_magnitude_confidence = np.mean([p['magnitude_confidence'] for p in predictions.values()])
                
                f.write("=== æ€»ä½“ç»Ÿè®¡ ===\n")
                f.write(f"é¢„æµ‹è‚¡ç¥¨æ€»æ•°: {total_stocks}\n")
                f.write(f"é¢„æµ‹ä¸Šæ¶¨è‚¡ç¥¨æ•°: {up_count} ({up_count/total_stocks:.1%})\n")
                f.write(f"é¢„æµ‹ä¸‹è·Œè‚¡ç¥¨æ•°: {down_count} ({down_count/total_stocks:.1%})\n")
                f.write(f"å¹³å‡æ–¹å‘é¢„æµ‹ç½®ä¿¡åº¦: {avg_direction_confidence:.2%}\n")
                f.write(f"å¹³å‡å¹…åº¦é¢„æµ‹ç½®ä¿¡åº¦: {avg_magnitude_confidence:.2%}\n\n")
                
                # å¹…åº¦åˆ†å¸ƒ
                magnitude_counts = {}
                for p in predictions.values():
                    mag = p['predicted_magnitude']
                    magnitude_counts[mag] = magnitude_counts.get(mag, 0) + 1
                
                f.write("=== å¹…åº¦é¢„æµ‹åˆ†å¸ƒ ===\n")
                magnitude_names = ["ä¸‹è·Œ", "æ¨ªç›˜", "ä¸Šæ¶¨"]
                for i, name in enumerate(magnitude_names):
                    count = magnitude_counts.get(i, 0)
                    f.write(f"{name}: {count} åª ({count/total_stocks:.1%})\n")
                f.write("\n")
                
                # è¯¦ç»†ç»“æœ
                f.write("=== è¯¦ç»†é¢„æµ‹ç»“æœ ===\n")
                f.write("è‚¡ç¥¨ä»£ç \té¢„æµ‹ä»·æ ¼\tæ–¹å‘\tæ–¹å‘ç½®ä¿¡åº¦\tå¹…åº¦\tå¹…åº¦ç½®ä¿¡åº¦\tæ•°æ®ç‚¹æ•°\n")
                
                for stock_code, result in predictions.items():
                    direction_text = "ä¸Šæ¶¨" if result['predicted_direction'] == 1 else "ä¸‹è·Œ"
                    magnitude_text = ["ä¸‹è·Œ", "æ¨ªç›˜", "ä¸Šæ¶¨"][result['predicted_magnitude']]
                    
                    f.write(f"{stock_code}\t"
                           f"{result['predicted_price']:.4f}\t"
                           f"{direction_text}\t"
                           f"{result['direction_confidence']:.2%}\t"
                           f"{magnitude_text}\t"
                           f"{result['magnitude_confidence']:.2%}\t"
                           f"{result['data_points']}\n")
                
                # æ¨¡å‹ä¿¡æ¯
                f.write("\n=== æ¨¡å‹ä¿¡æ¯ ===\n")
                f.write(f"æ¨¡å‹è·¯å¾„: {self.model_path}\n")
                if self.config is not None:
                    f.write(f"åºåˆ—é•¿åº¦: {self.config['seq_length']}\n")
                    f.write(f"æ¨¡å‹ç»´åº¦: {self.config['d_model']}\n")
                    f.write(f"æ³¨æ„åŠ›å¤´æ•°: {self.config['nhead']}\n")
                    f.write(f"å±‚æ•°: {self.config['num_layers']}\n")
                    f.write(f"Dropout: {self.config['dropout']}\n")
                    f.write(f"é¢„æµ‹å¤©æ•°: {self.config['prediction_days']}\n")
                else:
                    f.write("æ¨¡å‹é…ç½®: æœªåŠ è½½\n")
                
                # æ€§èƒ½è¯„ä¼°
                f.write("\n=== æ€§èƒ½è¯„ä¼° ===\n")
                if avg_direction_confidence > 0.7:
                    f.write("æ–¹å‘é¢„æµ‹ç½®ä¿¡åº¦: é«˜ (>70%)\n")
                elif avg_direction_confidence > 0.5:
                    f.write("æ–¹å‘é¢„æµ‹ç½®ä¿¡åº¦: ä¸­ç­‰ (50-70%)\n")
                else:
                    f.write("æ–¹å‘é¢„æµ‹ç½®ä¿¡åº¦: ä½ (<50%)\n")
                
                if avg_magnitude_confidence > 0.6:
                    f.write("å¹…åº¦é¢„æµ‹ç½®ä¿¡åº¦: é«˜ (>60%)\n")
                elif avg_magnitude_confidence > 0.4:
                    f.write("å¹…åº¦é¢„æµ‹ç½®ä¿¡åº¦: ä¸­ç­‰ (40-60%)\n")
                else:
                    f.write("å¹…åº¦é¢„æµ‹ç½®ä¿¡åº¦: ä½ (<40%)\n")
                
                f.write("\nè¯¦ç»†é¢„æµ‹ç»“æœï¼ˆéƒ¨åˆ†ï¼‰ï¼š\n")
                # ä¿®æ­£ï¼šæ”¯æŒdictæˆ–listç±»å‹çš„predictions
                if isinstance(predictions, dict):
                    pred_list = list(predictions.values())
                else:
                    pred_list = predictions
                for pred in pred_list[:10]:
                    f.write(str(pred) + "\n")
            
            print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")
            return None
    
    def visualize_predictions(self, predictions, output_path="../../results/predictions/prediction_visualization.png"):
        """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""
        print("ğŸ“Š æ­£åœ¨ç”Ÿæˆé¢„æµ‹å¯è§†åŒ–...")
        
        try:
            if not predictions:
                print("âŒ æ— é¢„æµ‹æ•°æ®å¯å¯è§†åŒ–")
                return None
            
            # åˆ›å»ºå›¾å½¢
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('å¤šä»»åŠ¡å­¦ä¹ è‚¡ç¥¨é¢„æµ‹ç»“æœå¯è§†åŒ–', fontsize=16, fontweight='bold')
            
            # 1. æ–¹å‘é¢„æµ‹åˆ†å¸ƒ
            directions = [p['predicted_direction'] for p in predictions.values()]
            direction_counts = [directions.count(0), directions.count(1)]
            direction_labels = ['ä¸‹è·Œ', 'ä¸Šæ¶¨']
            
            axes[0, 0].pie(direction_counts, labels=direction_labels, autopct='%1.1f%%', startangle=90)
            axes[0, 0].set_title('æ–¹å‘é¢„æµ‹åˆ†å¸ƒ')
            
            # 2. å¹…åº¦é¢„æµ‹åˆ†å¸ƒ
            magnitudes = [p['predicted_magnitude'] for p in predictions.values()]
            magnitude_counts = [magnitudes.count(0), magnitudes.count(1), magnitudes.count(2)]
            magnitude_labels = ['ä¸‹è·Œ', 'æ¨ªç›˜', 'ä¸Šæ¶¨']
            
            axes[0, 1].bar(magnitude_labels, magnitude_counts, color=['red', 'gray', 'green'])
            axes[0, 1].set_title('å¹…åº¦é¢„æµ‹åˆ†å¸ƒ')
            axes[0, 1].set_ylabel('è‚¡ç¥¨æ•°é‡')
            
            # 3. ç½®ä¿¡åº¦åˆ†å¸ƒ
            direction_confidences = [p['direction_confidence'] for p in predictions.values()]
            magnitude_confidences = [p['magnitude_confidence'] for p in predictions.values()]
            
            axes[1, 0].hist(direction_confidences, bins=20, alpha=0.7, label='æ–¹å‘é¢„æµ‹', color='blue')
            axes[1, 0].hist(magnitude_confidences, bins=20, alpha=0.7, label='å¹…åº¦é¢„æµ‹', color='orange')
            axes[1, 0].set_title('é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ')
            axes[1, 0].set_xlabel('ç½®ä¿¡åº¦')
            axes[1, 0].set_ylabel('é¢‘æ¬¡')
            axes[1, 0].legend()
            
            # 4. ä»·æ ¼é¢„æµ‹åˆ†å¸ƒ
            predicted_prices = [p['predicted_price'] for p in predictions.values()]
            last_prices = [p['last_close'] for p in predictions.values()]
            
            axes[1, 1].scatter(last_prices, predicted_prices, alpha=0.6)
            axes[1, 1].plot([min(last_prices), max(last_prices)], [min(last_prices), max(last_prices)], 'r--', lw=2)
            axes[1, 1].set_title('é¢„æµ‹ä»·æ ¼ vs æœ€åæ”¶ç›˜ä»·')
            axes[1, 1].set_xlabel('æœ€åæ”¶ç›˜ä»·')
            axes[1, 1].set_ylabel('é¢„æµ‹ä»·æ ¼')
            
            plt.tight_layout()
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            plt.show()
            
            print(f"âœ… å¯è§†åŒ–å·²ä¿å­˜åˆ°: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¯è§†åŒ–æ—¶å‡ºé”™: {e}")
            return None
    
    def run_prediction_pipeline(self, data_path="../../data/test_csv"):
        """è¿è¡Œå®Œæ•´çš„é¢„æµ‹æµç¨‹"""
        print("ğŸš€ å¼€å§‹è¿è¡Œå¤šä»»åŠ¡å­¦ä¹ é¢„æµ‹æµç¨‹...")
        
        try:
            # 1. é¢„æµ‹æ‰€æœ‰è‚¡ç¥¨
            predictions = self.predict_all_stocks(data_path)
            if predictions is None:
                print("âŒ é¢„æµ‹å¤±è´¥")
                return False
            
            # 2. ä¿å­˜é¢„æµ‹ç»“æœåˆ°CSV
            prediction_csv_path = self.save_predictions_to_csv(predictions)
            if prediction_csv_path is None:
                print("âŒ ä¿å­˜é¢„æµ‹ç»“æœå¤±è´¥")
                return False
            
            # 3. ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š
            report_path = self.generate_prediction_report(predictions)
            
            # 4. ç”Ÿæˆå¯è§†åŒ–
            viz_path = self.visualize_predictions(predictions)
            
            print("âœ… å¤šä»»åŠ¡å­¦ä¹ é¢„æµ‹æµç¨‹å®Œæˆ!")
            print(f"ğŸ“„ é¢„æµ‹æ•°æ®æ–‡ä»¶: {prediction_csv_path}")
            if report_path:
                print(f"ğŸ“„ é¢„æµ‹æŠ¥å‘Šæ–‡ä»¶: {report_path}")
            if viz_path:
                print(f"ğŸ“Š å¯è§†åŒ–æ–‡ä»¶: {viz_path}")
            return True
                
        except Exception as e:
            print(f"âŒ è¿è¡Œé¢„æµ‹æµç¨‹æ—¶å‡ºé”™: {e}")
            return False

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("=" * 60)
    print("ğŸš€ æ”¹è¿›ç‰ˆå¤šä»»åŠ¡å­¦ä¹ è‚¡ç¥¨é¢„æµ‹ç¨‹åºå¯åŠ¨")
    print("=" * 60)
    
    try:
        # è®¾ç½®è·¯å¾„
        model_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../models/best_improved_model.pth'))
        data_path = "../../data/test_csv"
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²è®­ç»ƒå¹¶ä¿å­˜åœ¨æ­£ç¡®ä½ç½®")
            return False
        
        # æ£€æŸ¥æµ‹è¯•æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(data_path):
            print(f"âŒ æµ‹è¯•æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_path}")
            print("è¯·ç¡®ä¿æµ‹è¯•æ•°æ®ç›®å½•å­˜åœ¨ä¸”åŒ…å«è‚¡ç¥¨æ•°æ®æ–‡ä»¶")
            return False
        
        # åˆ›å»ºé¢„æµ‹å™¨
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æ”¹è¿›ç‰ˆé¢„æµ‹å™¨...")
        predictor = ImprovedStockPredictor(model_path=model_path)
        
        # è¿è¡Œé¢„æµ‹æµç¨‹
        success = predictor.run_prediction_pipeline(data_path=data_path)
        
        if success:
            print("\n" + "=" * 60)
            print("âœ… æ”¹è¿›ç‰ˆé¢„æµ‹ç¨‹åºæ‰§è¡ŒæˆåŠŸ!")
            print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
            print("   - é¢„æµ‹æ•°æ®: ../../data/Adjustment_csv/å¤šä»»åŠ¡é¢„æµ‹ç»“æœ.csv")
            print("   - é¢„æµ‹æŠ¥å‘Š: ../../data/Adjustment_csv/å¤šä»»åŠ¡é¢„æµ‹æŠ¥å‘Š.txt")
            print("   - å¯è§†åŒ–: ../../results/predictions/prediction_visualization.png")
            print("=" * 60)
            return True
        else:
            print("\n" + "=" * 60)
            print("âŒ æ”¹è¿›ç‰ˆé¢„æµ‹ç¨‹åºæ‰§è¡Œå¤±è´¥!")
            print("=" * 60)
            return False
            
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    # è¿è¡Œä¸»ç¨‹åº
    success = main()
    
    if success:
        print("\nğŸ‰ æ”¹è¿›ç‰ˆé¢„æµ‹ç¨‹åºæ‰§è¡Œå®Œæˆï¼Œè¯·æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶!")
    else:
        print("\nğŸ’¡ ç¨‹åºæ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹:")
        print("   1. æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶ä¸”è·¯å¾„æ­£ç¡®")
        print("   2. æµ‹è¯•æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨å¹¶åŒ…å«CSVæ–‡ä»¶")
        print("   3. æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®(åŒ…å«secucode,open,high,low,close,volåˆ—)")
        print("   4. æ¨¡å‹é…ç½®æ–‡ä»¶æ˜¯å¦åŒ¹é…")
        
    input("\næŒ‰ä»»æ„é”®é€€å‡º...")